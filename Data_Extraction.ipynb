{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 849006448625426431\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 815272576222011392\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 758031374418714624\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 699301786079723519\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 651901980755890175\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 584460448864542719\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 547886092452503551\n",
      "...1599 tweets downloaded so far\n",
      "getting tweets before 520641455623516160\n",
      "...1798 tweets downloaded so far\n",
      "getting tweets before 482918155598458879\n",
      "...1996 tweets downloaded so far\n",
      "getting tweets before 458680816466284543\n",
      "...2195 tweets downloaded so far\n",
      "getting tweets before 433025285877796863\n",
      "...2395 tweets downloaded so far\n",
      "getting tweets before 404763080338726912\n",
      "...2594 tweets downloaded so far\n",
      "getting tweets before 380014283716710400\n",
      "...2793 tweets downloaded so far\n",
      "getting tweets before 364034671786471423\n",
      "...2992 tweets downloaded so far\n",
      "getting tweets before 352151980027813889\n",
      "...3191 tweets downloaded so far\n",
      "getting tweets before 345994600667824128\n",
      "...3221 tweets downloaded so far\n",
      "getting tweets before 344839494849146879\n",
      "...3221 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "#Extract data from twitter\n",
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "\n",
    "#Twitter API credentials\n",
    "consumer_key = '<consumer_key>'\n",
    "consumer_secret = '<consumer_secret>'\n",
    "access_key = '<access_key>'\n",
    "access_secret = '<access_secret>'\n",
    "\n",
    "\n",
    "def get_all_tweets(screen_name):\n",
    "#Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "\n",
    "#authorize twitter, initialize tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#initialize a list to hold all the tweepy Tweets\n",
    "alltweets = []\t\n",
    "\n",
    "#make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "new_tweets = api.user_timeline(screen_name = screen_name,count=200)\n",
    "\n",
    "#save most recent tweets\n",
    "alltweets.extend(new_tweets)\n",
    "\n",
    "#save the id of the oldest tweet less one\n",
    "oldest = alltweets[-1].id - 1\n",
    "\n",
    "#keep grabbing tweets until there are no tweets left to grab\n",
    "while len(new_tweets) > 0:\n",
    "print \"getting tweets before %s\" % (oldest)\n",
    "\n",
    "#all subsiquent requests use the max_id param to prevent duplicates\n",
    "new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "#save most recent tweets\n",
    "alltweets.extend(new_tweets)\n",
    "\n",
    "#update the id of the oldest tweet less one\n",
    "oldest = alltweets[-1].id - 1\n",
    "\n",
    "print \"...%s tweets downloaded so far\" % (len(alltweets))\n",
    "\n",
    "#transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "outtweets = [[tweet.id_str, tweet.author.name, tweet.created_at, tweet.text.encode(\"utf-8\"), tweet.retweet_count, tweet.favorite_count, tweet.source, tweet.author.followers_count, tweet.author.verified] for tweet in alltweets]\n",
    "\n",
    "#write the csv\t\n",
    "with open('%s_tweets.csv' % screen_name, 'wb') as f:\n",
    "writer = csv.writer(f)\n",
    "writer.writerow([\"id\", \"name\", \"created_at\",\"text\", \"retweets\", \"favorites\", \"source\", \"followers\", \"verified\"])\n",
    "writer.writerows(outtweets)\n",
    "\n",
    "pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#pass in the username of the account you want to download\n",
    "get_all_tweets(\"pitbull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge csv files with header from only the first file\n",
    "import pandas as pd\n",
    "import glob\n",
    "interesting_files = glob.glob(\"*.csv\")\n",
    "df_list = []\n",
    "for filename in sorted(interesting_files):\n",
    "    df_list.append(pd.read_csv(filename))\n",
    "full_df = pd.concat(df_list)\n",
    "\n",
    "full_df.to_csv('all_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
