{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.912e+02   2.312e+04   3.694e+03   1.796e+01   1.525e+01   5.358e+01\n",
      "   3.044e+01   6.289e+01   1.286e+01   2.216e+01   1.622e+02   5.093e+00\n",
      "   4.295e+01   1.112e+01   1.313e+01   1.905e+01   6.502e+00   1.125e+02\n",
      "   4.104e+01   5.486e+01   9.338e+01   1.198e+02   6.040e+01   7.138e+00\n",
      "   3.944e+01]\n",
      "[[ 2.  0.  1.  0.]\n",
      " [ 1.  0.  1.  0.]\n",
      " [ 1.  1.  0.  0.]\n",
      " [ 1.  1.  2.  0.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "# load data\n",
    "data_df = pd.read_csv('C:\\Temp\\weets.csv')\n",
    "array = data_df.values\n",
    "X = array[:,0:25]\n",
    "Y = array[:,25]\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "# summarize scores\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [False  True  True False False False False False  True False False False\n",
      " False False False False False False False False False False False False\n",
      " False]\n",
      "Feature Ranking: [15  1  1  9 16 12  8 22  1 18  7 21  3 19 14 10 17  5  4  2 20  6 13 23 11]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with RFE\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load data\n",
    "data_df = pd.read_csv('C:\\Temp\\weets.csv')\n",
    "array = data_df.values\n",
    "X = array[:,0:25]\n",
    "Y = array[:,25]\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: %d\") % fit.n_features_\n",
    "print(\"Selected Features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [ 0.397  0.256  0.119]\n",
      "[[  2.469e-01   9.684e-01  -2.543e-02   1.057e-02  -6.688e-04  -2.461e-03\n",
      "   -8.875e-04  -2.693e-03  -2.469e-04  -5.218e-04  -6.550e-03  -3.754e-04\n",
      "   -1.027e-03  -1.168e-03   5.066e-04  -5.035e-04   4.224e-04   1.521e-02\n",
      "   -2.961e-04  -4.960e-05  -5.892e-03  -6.162e-03   5.426e-03  -3.083e-03\n",
      "    9.432e-04]\n",
      " [  9.535e-01  -2.388e-01   1.795e-01  -1.482e-03  -7.474e-04  -3.996e-03\n",
      "   -1.229e-03  -5.117e-03  -2.068e-04  -8.394e-04  -1.616e-02  -1.722e-04\n",
      "   -6.992e-04  -9.681e-03  -8.397e-04  -2.560e-03  -3.123e-04   1.327e-03\n",
      "   -1.200e-03  -1.632e-03  -3.052e-02  -1.754e-02  -2.549e-03  -1.819e-03\n",
      "    7.127e-04]\n",
      " [ -1.713e-01   6.841e-02   9.770e-01  -1.526e-02  -2.315e-03  -8.005e-03\n",
      "   -3.410e-03  -1.257e-02  -7.825e-04  -3.669e-03  -4.196e-02  -1.650e-03\n",
      "   -3.350e-03  -1.012e-02   3.109e-03  -3.677e-03  -2.123e-03  -2.518e-03\n",
      "   -2.419e-03  -1.587e-03  -8.212e-02  -4.632e-02  -7.522e-03  -4.277e-03\n",
      "   -3.471e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with PCA\n",
    "import numpy\n",
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA\n",
    "# load data\n",
    "data_df = pd.read_csv('C:\\Temp\\weets.csv')\n",
    "array = data_df.values\n",
    "X = array[:,0:25]\n",
    "Y = array[:,25]\n",
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\") % fit.explained_variance_ratio_\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.084  0.53   0.158  0.018  0.004  0.007  0.003  0.006  0.002  0.004\n",
      "  0.013  0.004  0.003  0.019  0.008  0.008  0.007  0.022  0.004  0.006\n",
      "  0.028  0.018  0.017  0.013  0.016]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# load data\n",
    "data_df = pd.read_csv('C:\\Temp\\weets.csv')\n",
    "array = data_df.values\n",
    "X = array[:,0:25]\n",
    "Y = array[:,25]\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
